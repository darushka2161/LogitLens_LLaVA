# Интерпретация мультимодальной модели LLaVA с использованием LogitLens

## Эксперименты

### Исследуемые изображения

Были выбраны четыре изображения различной сложности — от однородной текстуры до насыщенного коллажа:

| № | Изображение | Характеристика | Ответ модели |
|--:|-------------|----------------|--------------|
| 1 | ![Img1](https://i.pinimg.com/736x/2b/91/29/2b9129cf45f28dc2363a230b7b2069da.jpg) | Сплошная пурпурная ткань | "a blanket of a vivid purple hue" |
| 2 | ![Img2](https://i.pinimg.com/736x/96/df/e9/96dfe96d6a77a9eac20f2e05bcbcd5e3.jpg) | Ткань с узором | "a silky texture and light/dark purple patterns" |
| 3 | ![Img3](https://i.pinimg.com/736x/01/f0/0b/01f00baf3337be08c0c58a5b3fc41ecc.jpg) | Игрушка на фоне цветов | "a toy-like cat standing within a mass of purple flowers" |
| 4 | ![Img4](https://i.pinimg.com/736x/37/ef/f9/37eff97754219d7a5757edd601f37bd9.jpg) | Коллаж с людьми и стикерами | "a collage of various images featuring people and bandanas..." |

---

## Как работает вставка изображения

Модель LLaVA использует токен `<image>`, который вставляется внутрь текстового prompt’а. Затем:

1. Изображение проходит через `vision_tower` (CLIP).
2. Полученные визуальные эмбеддинги подаются в `multi_modal_projector`.
3. Эти проецированные эмбеддинги заменяют токен `<image>` в последовательности текстовых эмбеддингов.
4. Объединённая последовательность подаётся в языковую модель (`language_model`), интерпретируемую с помощью `HookedTransformer`.

---

## Анализ и интерпретация

### A. Какие изменения происходят в логитах по мере движения от первых к последним блокам LLM?

Механизм LogitLens позволяет проецировать скрытые состояния каждого слоя обратно в пространство токенов, что помогает отслеживать динамику предсказаний модели.

**Наблюдения:**

- На **ранних слоях** логиты были слабо дифференцированы: модель не делает предпочтений в выборе токена.
- На **средних слоях** начинают появляться выделенные кандидаты, в том числе визуально релевантные слова (`purple`, `fabric`).
- На **последних слоях** распределение логитов становится острым — 1–2 токена доминируют, что указывает на принятие "решения" моделью.

Это соответствует типичному поведению трансформеров: от сбора контекста к уточнённой генерации.

---

### B. Есть ли интересные паттерны в логитах в зависимости от типа изображений?

**Да,** поведение модели варьировалось в зависимости от сложности изображения.

- **Изображения с текстурой (1, 2):**
  - Модель описывает цвет, фактуру и материал.
  - Выбор токенов стабилен и краток, ответы однообразны.
  
- **Изображение с объектом (3):**
  - Модель уверенно определяет наличие объекта (`cat`) и контекст (`flowers`).
  - Генерация становится более конкретной, появляется разнообразие в лексике.
  
- **Сложное изображение (4):**
  - Ответ содержит больше перечислений (`collage`, `people`, `stickers`).
  - Визуализация attention-паттернов (на слоях 23, 28, 31) показывает фокусировку на различных частях текстового вывода.

**Вывод:** Сложные сцены приводят к более длинным и обобщённым описаниям, тогда как простые сцены вызывают более точные и короткие ответы.

---

### C. Сильно ли расходятся ваши ожидания с наблюдаемым поведением? Какие проблемы удалось увидеть?

**Совпадения с ожиданиями:**

- Модель уверенно справляется с распознаванием цвета, фактуры и базовых объектов.
- Ответы короткие и логичные на простых сценах.
- На поздних слоях внимание и логиты сужаются к финальным токенам.

**Что можно считать неожиданным или потенциально проблемным:**

- **Избыточная конкретизация:** Модель может делать предположения на основе узора — например, назвать ткань "blanket" без контекста.
- **Ограниченная детализация сложных изображений:** В коллаже с людьми модель описывает несколько элементов, но не показывает уверенного фокуса.
- **Внимание к последним токенам:** Хотя визуализация attention-паттернов инициализирована, анализ явно показывает концентрацию внимания ближе к завершению ответа, но не позволяет количественно оценить фокус на `<image>` токене.

---

## Заключение

Использование LogitLens для анализа LLaVA-1.5 позволяет:

- Проследить, как изображение влияет на генерацию на уровне логитов.
- Выявить зависимости между сложностью изображения и характером ответа.
- Наблюдать эволюцию внимания и предсказаний по мере прохождения слоёв LLM.

Анализ подтверждает, что LLaVA демонстрирует разумную генерацию на простых изображениях, но может быть ограничена при обработке сложных сцен, особенно без явного контекста. Методика может быть полезна для диагностики и улучшения визуально-языковых моделей.
